{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Pruning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCD01S5zPBey"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/', force_remount=True)\n",
        "!ls /gdrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiHt7bXrPgaU"
      },
      "source": [
        "import os\n",
        "\n",
        "# BASE_PATH = '/gdrive/MyDrive/DL Final Project/' \n",
        "BASE_PATH = '/gdrive/My Drive/CSE 490G1543/DL Final Project/'â€©\n",
        "DATA_PATH = BASE_PATH + 'German/'\n",
        "\n",
        "os.chdir(BASE_PATH)\n",
        "os.chdir(DATA_PATH)\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQKJPNrhUA7n"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import h5py\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append(BASE_PATH)\n",
        "import seaborn as sns\n",
        "# sns.set_theme()\n",
        "import pt_util"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL4ztcb_UYEo"
      },
      "source": [
        "# Data loader\n",
        "class H5Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir='/gdrive/My Drive/CSE 490G1543/DL Final Project/German/', mode='train', transform=None):\n",
        "        h5_string = ''\n",
        "        if mode == 'train':\n",
        "          h5_string = 'Train.h5'\n",
        "        else:\n",
        "          h5_string = 'Test.h5'\n",
        "        \n",
        "        self.transform = transform\n",
        "        temp = os.path.join(data_dir, h5_string)\n",
        "        self.h5_file = h5py.File(temp, 'r')\n",
        "        self.images = self.h5_file['Data'][:]\n",
        "        self.labels = torch.LongTensor(self.h5_file['Labels'][:])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "      \n",
        "    def __getitem__(self, idx):\n",
        "        data = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "        return (data.type(torch.FloatTensor), label)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsk7DL3Yg6a5"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY20ri6AnW0D"
      },
      "source": [
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "class TheNet(nn.Module):\n",
        "  def __init__(self, out_size):\n",
        "    super(TheNet, self).__init__()\n",
        "    self.net = models.vgg19_bn(pretrained=True)\n",
        "    self.fc = nn.Linear(1000, out_size)\n",
        "    self.accuracy = None\n",
        "  \n",
        "    features = list(models.vgg19_bn(pretrained = True).features)[:]\n",
        "    self.features = nn.ModuleList(features).eval() \n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x1 = self.net(x)\n",
        "    x2 = self.fc(x1)\n",
        "\n",
        "    results = []\n",
        "    for ii,model in enumerate(self.features):\n",
        "        x = model(x)\n",
        "        results.append(x)\n",
        "\n",
        "    return x2, results\n",
        "\n",
        "  def loss(self, prediction, label, reduction='mean'):\n",
        "    loss_val = F.cross_entropy(prediction, label.squeeze(), reduction=reduction)\n",
        "    return loss_val"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92XcT_yNUopr"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "  model.train()\n",
        "  losses = []\n",
        "  for batch_idx, (data, label) in enumerate(train_loader):\n",
        "    data, label = data.to(device), label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output, _ = model(data)\n",
        "    loss = model.loss(output, label)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          time.ctime(time.time()),\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "  return np.mean(losses)\n",
        "\n",
        "def test(model, device, test_loader, log_interval=None):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (data, label) in enumerate(test_loader):\n",
        "      data, label = data.to(device), label.to(device)\n",
        "      output, _ = model(data)\n",
        "      test_loss_on = model.loss(output, label, reduction='sum').item()\n",
        "      test_loss += test_loss_on\n",
        "      pred = output.max(1)[1]\n",
        "      correct_mask = pred.eq(label.view_as(pred))\n",
        "      num_correct = correct_mask.sum().item()\n",
        "      correct += num_correct\n",
        "      if log_interval is not None and batch_idx % log_interval == 0:\n",
        "        print('{} Test: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            time.ctime(time.time()),\n",
        "            batch_idx * len(data), len(test_loader.dataset),\n",
        "            100. * batch_idx / len(test_loader), test_loss_on))\n",
        "        \n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          test_loss, correct, len(test_loader.dataset), test_accuracy))\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fb51lHWlCKv"
      },
      "source": [
        "from copy import deepcopy\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def prune(model, data, d_labels, layer_indices, prune_method=\"l2\", prune_ratio=0.5):\n",
        "    pruned_model = deepcopy(model)\n",
        "    if prune_ratio == 1:\n",
        "        return pruned_model\n",
        "\n",
        "    if prune_method != \"kmeans\":\n",
        "        out, results = model.forward(data)\n",
        "\n",
        "    if prune_method == \"gradient\":\n",
        "        loss = model.loss(out, d_labels)\n",
        "        loss.backward()\n",
        "\n",
        "    state_dict = pruned_model.state_dict()\n",
        "\n",
        "    for idx in layer_indices:\n",
        "        \n",
        "        # Keys for the state dict\n",
        "        key_w = \"net.features.\" + str(idx) + \".weight\"\n",
        "        key_b = \"net.features.\" + str(idx) + \".bias\"\n",
        "\n",
        "        # Find indices based on pruning method\n",
        "        if prune_method == \"l2\" or prune_method == \"hrank\":  # label-free\n",
        "            # Get activations\n",
        "            activations = results[idx].detach().numpy()\n",
        "            activations = np.maximum(activations, 0)\n",
        "            k = int(activations.shape[1] * (1-prune_ratio))\n",
        "\n",
        "            if prune_method == \"l2\":\n",
        "                # Get the l2-norm of the n x w x h vector that belongs to a single filter\n",
        "                activations = np.reshape(activations, (activations.shape[1], -1))\n",
        "                norms = np.linalg.norm(activations, axis=1)\n",
        "\n",
        "                # Prune the k lowest-norm filters\n",
        "                indices = norms.argsort()[:k]\n",
        "\n",
        "            else:  # prune_method == \"hrank\"\n",
        "                # Create an empty ranks matrix of n x num_filters\n",
        "                ranks = np.zeros((activations.shape[0], activations.shape[1])) # 2048, 64\n",
        "                \n",
        "                # Calculate the rank of each output\n",
        "                for filter_idx in range(activations.shape[1]):\n",
        "                    for sample_idx in range(activations.shape[0]):\n",
        "                        ranks[sample_idx,filter_idx] = np.linalg.matrix_rank(activations[sample_idx, filter_idx, :, :])\n",
        "                \n",
        "                # Average the ranks, collapsing the batch dimension (n)\n",
        "                ranks = np.mean(ranks, axis=0)\n",
        "\n",
        "                # Prune the k lowest-average-rank filters\n",
        "                indices = ranks.argsort()[:k]\n",
        "\n",
        "        elif prune_method == \"kmeans\":  # data-free\n",
        "            # Get filters\n",
        "            filters = state_dict[key_w].detach().numpy()\n",
        "            filters = np.reshape(filters, (filters.shape[0], -1))\n",
        "            \n",
        "            # Perform kmeans clustering on the filters\n",
        "            k = int(prune_ratio * filters.shape[0])\n",
        "            kmeans = KMeans(n_clusters=k, random_state=0).fit(filters)\n",
        "\n",
        "            centroids = kmeans.cluster_centers_\n",
        "            labels = kmeans.labels_\n",
        "            indices = []\n",
        "\n",
        "            # Find representative filters that are closest to the centroids.\n",
        "            # We are NOT using the centroids themselves as filters\n",
        "            for i in range(centroids.shape[0]):\n",
        "                curr_indices = np.where(labels == i)[0]\n",
        "                diff = np.linalg.norm(filters[curr_indices] - centroids[i], axis=1)\n",
        "                to_prune = diff.argsort()[1:]\n",
        "                indices.extend(currr_indices[to_prune])\n",
        "\n",
        "        else:  # label-dependent (gradient)\n",
        "            # Get the filters\n",
        "            filters = state_dict[key_w].detach().numpy() \n",
        "            # Get the gradients\n",
        "            grad = model.net.features[idx].weight.grad.numpy()\n",
        "            # Multiply the gradients with the filters\n",
        "            scores = np.abs(grad * filters)\n",
        "            scores = np.reshape(scores, (scores.shape[0], -1))\n",
        "\n",
        "            # Calculate the sizes (norms) of each filter x gradient \"score\"\n",
        "            scores = np.linalg.norm(scores, axis=1)\n",
        "\n",
        "            k = int(filters.shape[0] * (1-prune_ratio))\n",
        "\n",
        "            # Prune the k lowest-score filters\n",
        "            indices = scores.argsort()[:k]\n",
        "\n",
        "        # Perform the pruning for indices found\n",
        "        pruned_model.state_dict()[key_w][indices,:,:,:] = 0\n",
        "        pruned_model.state_dict()[key_b][indices] = 0\n",
        "        \n",
        "        # Zeroing out the same batchnorm parameters \n",
        "        key_w_bn = \"net.features.\" + str(idx + 1) + \".weight\"\n",
        "        key_b_bn = \"net.features.\" + str(idx + 1) + \".bias\"\n",
        "        key_mu_bn = \"net.features.\" + str(idx + 1) + \".running_mean\"\n",
        "        key_sig_bn = \"net.features.\" + str(idx + 1) + \".running_var\"\n",
        "        pruned_model.state_dict()[key_w_bn][indices] = 0\n",
        "        pruned_model.state_dict()[key_b_bn][indices] = 0\n",
        "        pruned_model.state_dict()[key_mu_bn][indices] = 0\n",
        "        pruned_model.state_dict()[key_sig_bn][indices] = 0\n",
        "\n",
        "    return pruned_model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCRVLeG9Wpc_"
      },
      "source": [
        "def prune_experiment(original_model, prune_type, single_batch, single_lab, ratios, exp_num):\n",
        "\n",
        "    vgg11_conv_idx = [0,3,6,8,11,13,16,18]\n",
        "    vgg19_conv_idx = [0, 3, 7, 10, 14, 17, 20, 23, 27, 30, 33, 36, 40, 43, 46, 49]\n",
        "\n",
        "    pruning_accs = []\n",
        "\n",
        "    for ratio in ratios:\n",
        "        \n",
        "        print(\"---------------------------------- \" + prune_type + \" \" + str(ratio) + \" ----------------------------------\")\n",
        "\n",
        "        pruned_model = prune(original_model, single_batch, single_lab, vgg19_conv_idx, prune_type, ratio)\n",
        "        \n",
        "        # Training hyperparameters\n",
        "        BATCH_SIZE = 16\n",
        "        TEST_BATCH_SIZE = 10\n",
        "        EPOCHS = 2\n",
        "        LEARNING_RATE = 0.001\n",
        "        MOMENTUM = 0.9\n",
        "        USE_CUDA = True\n",
        "        PRINT_INTERVAL = 10000\n",
        "        WEIGHT_DECAY = 0.0005\n",
        "\n",
        "        EXPERIMENT_VERSION = str(exp_num + ratio) #\"1.2\"\n",
        "        LOG_PATH = DATA_PATH + 'logs/' + EXPERIMENT_VERSION + '/'\n",
        "\n",
        "        use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "        print('Using device', device)\n",
        "        import multiprocessing\n",
        "        print('num cpus:', multiprocessing.cpu_count())\n",
        "\n",
        "        kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
        "                  'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(H5Dataset(DATA_PATH, 'train', transform=transform_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "        test_loader = torch.utils.data.DataLoader(H5Dataset(DATA_PATH, 'test', transform=transform_train), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        # return\n",
        "        model = pruned_model.to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "        start_epoch = 0\n",
        "\n",
        "        train_losses, test_losses, test_accuracies = pt_util.read_log(LOG_PATH + 'log.pkl', ([], [], []))\n",
        "        test_loss, test_accuracy = test(model, device, test_loader)\n",
        "\n",
        "        test_losses.append((start_epoch, test_loss))\n",
        "        test_accuracies.append((start_epoch, test_accuracy))\n",
        "\n",
        "        model = model.cpu()\n",
        "        for param_tensor in model.state_dict():\n",
        "            print(\"number of nonzero filters: \" + str(model.state_dict()[param_tensor].sum(dim=(1, 2, 3)).count_nonzero()))\n",
        "            break\n",
        "        model = model.to(device)\n",
        "        try:\n",
        "          for epoch in range(start_epoch, EPOCHS + 1):\n",
        "            train_loss = train(model, device, train_loader, optimizer, epoch, PRINT_INTERVAL)\n",
        "            test_loss, test_accuracy = test(model, device, test_loader)\n",
        "            test_accuracies.append((epoch, test_accuracy))\n",
        "            model = model.cpu()\n",
        "            for param_tensor in model.state_dict():\n",
        "                print(\"number of nonzero filters: \" + str(model.state_dict()[param_tensor].sum(dim=(1, 2, 3)).count_nonzero()))\n",
        "                break\n",
        "            model = model.to(device)\n",
        "        except KeyboardInterrupt as ke:\n",
        "          print('Interrupted')\n",
        "        except:\n",
        "          import traceback\n",
        "          traceback.print_exc()\n",
        "        finally:\n",
        "          pruning_accs.append(test_accuracies[-1][1])\n",
        "    return pruning_accs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsMPkXwQY0wp"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "original_model = TheNet(out_size=43)\n",
        "prune_loader = torch.utils.data.DataLoader(H5Dataset(DATA_PATH, 'train', transform=transform_train), batch_size=512, shuffle=True)\n",
        "single_batch,single_lab = next(iter(prune_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as7GMuE5uY1v"
      },
      "source": [
        "pruning_ratios = [0.75, 0.5, 0.25, .2, 0.15, 0.1, 0.05, 0.01]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL134OPzneZ5"
      },
      "source": [
        "baseline_accuracy = prune_experiment(original_model, \"l2\", single_batch, single_lab, [1], 10)\n",
        "print(\"BASELINE ACCURACY:\")\n",
        "print(baseline_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50bBzRATYsj_"
      },
      "source": [
        "grad_accuracies = prune_experiment(original_model, \"gradient\", single_batch, single_lab, pruning_ratios, 10)\n",
        "print(\"GRAD BASED PRUNING ACCURACY:\")\n",
        "print(grad_accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1nTUz1endlY"
      },
      "source": [
        "l2_accuracies = prune_experiment(original_model, \"l2\", single_batch, single_lab, pruning_ratios, 11)\n",
        "print(\"L2 PRUNING ACCURACY:\")\n",
        "print(l2_accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdyHMJJVZBY6"
      },
      "source": [
        "hrank_accuracies = prune_experiment(original_model, \"hrank\", single_batch, single_lab, pruning_ratios, 12)\n",
        "print(\"HRANK PRUNING ACCURACY:\")\n",
        "print(hrank_accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9jrkgecnm3r"
      },
      "source": [
        "kmeans_accuracies = prune_experiment(original_model, \"kmeans\", single_batch, single_lab, pruning_ratios, 13)\n",
        "print(\"KMEANS PRUNING ACCURACY:\")\n",
        "print(kmeans_accuracies)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}